{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1775f0b1-9f6c-4551-9b39-24d52b954ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import GPy\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.linalg        import cho_factor, cho_solve\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.optimize      import minimize\n",
    "from scipy.linalg import svd, cholesky, eigh\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68fabb50-ee00-4929-8c98-8783c709cd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "districts = pd.read_csv(\"postaldistricts.txt\", names=[\"district\", \"blank\", \"easting\", \"northing\", \"lat\", \"long\", \"NGR\",\"grid\",\"sources\"], usecols=range(9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42fbf9b5-aafd-4206-82b4-815327e6c446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>district</th>\n",
       "      <th>blank</th>\n",
       "      <th>easting</th>\n",
       "      <th>northing</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>NGR</th>\n",
       "      <th>grid</th>\n",
       "      <th>sources</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AB1</td>\n",
       "      <td>###</td>\n",
       "      <td>383656</td>\n",
       "      <td>760468</td>\n",
       "      <td>56.735562</td>\n",
       "      <td>-2.268770</td>\n",
       "      <td>NO 836604</td>\n",
       "      <td>osgb</td>\n",
       "      <td>NPE Postcode web submission</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AB10</td>\n",
       "      <td>###</td>\n",
       "      <td>392567</td>\n",
       "      <td>804537</td>\n",
       "      <td>57.131679</td>\n",
       "      <td>-2.124423</td>\n",
       "      <td>NJ 92545</td>\n",
       "      <td>osgb</td>\n",
       "      <td>Dracos.co.uk Postbox Importer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AB11</td>\n",
       "      <td>###</td>\n",
       "      <td>394533</td>\n",
       "      <td>805406</td>\n",
       "      <td>57.139507</td>\n",
       "      <td>-2.091960</td>\n",
       "      <td>NJ 94554</td>\n",
       "      <td>osgb</td>\n",
       "      <td>Dracos.co.uk Postbox Importer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AB12</td>\n",
       "      <td>###</td>\n",
       "      <td>393057</td>\n",
       "      <td>800339</td>\n",
       "      <td>57.093971</td>\n",
       "      <td>-2.116218</td>\n",
       "      <td>NJ 9303</td>\n",
       "      <td>osgb</td>\n",
       "      <td>Dracos.co.uk Postbox Importer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AB13</td>\n",
       "      <td>###</td>\n",
       "      <td>387085</td>\n",
       "      <td>802538</td>\n",
       "      <td>57.113599</td>\n",
       "      <td>-2.214879</td>\n",
       "      <td>NJ 87025</td>\n",
       "      <td>osgb</td>\n",
       "      <td>NPE Postcode web submission</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3131</th>\n",
       "      <td>YO91</td>\n",
       "      <td>###</td>\n",
       "      <td>460504</td>\n",
       "      <td>453656</td>\n",
       "      <td>53.975455</td>\n",
       "      <td>-1.079029</td>\n",
       "      <td>SE 605536</td>\n",
       "      <td>osgb</td>\n",
       "      <td>NPE Postcode web submission</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3132</th>\n",
       "      <td>YS22</td>\n",
       "      <td>###</td>\n",
       "      <td>493648</td>\n",
       "      <td>507760</td>\n",
       "      <td>54.456617</td>\n",
       "      <td>-0.557006</td>\n",
       "      <td>NZ 93677</td>\n",
       "      <td>osgb</td>\n",
       "      <td>NPE Postcode web submission</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3133</th>\n",
       "      <td>ZE1</td>\n",
       "      <td>###</td>\n",
       "      <td>446297</td>\n",
       "      <td>1141020</td>\n",
       "      <td>60.151066</td>\n",
       "      <td>-1.167983</td>\n",
       "      <td>HU 462410</td>\n",
       "      <td>osgb</td>\n",
       "      <td>FreeThePostcode.org Importer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3134</th>\n",
       "      <td>ZE2</td>\n",
       "      <td>###</td>\n",
       "      <td>444046</td>\n",
       "      <td>1168116</td>\n",
       "      <td>60.394585</td>\n",
       "      <td>-1.202625</td>\n",
       "      <td>HU 440681</td>\n",
       "      <td>osgb</td>\n",
       "      <td>Dracos.co.uk Postbox Importer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3135</th>\n",
       "      <td>ZE3</td>\n",
       "      <td>###</td>\n",
       "      <td>439134</td>\n",
       "      <td>967886</td>\n",
       "      <td>58.597195</td>\n",
       "      <td>-1.328406</td>\n",
       "      <td>NE 391678</td>\n",
       "      <td>osgb</td>\n",
       "      <td>FreeThePostcode.org Importer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3136 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     district blank  easting  northing        lat      long        NGR  grid  \\\n",
       "0         AB1   ###   383656    760468  56.735562 -2.268770  NO 836604  osgb   \n",
       "1        AB10   ###   392567    804537  57.131679 -2.124423   NJ 92545  osgb   \n",
       "2        AB11   ###   394533    805406  57.139507 -2.091960   NJ 94554  osgb   \n",
       "3        AB12   ###   393057    800339  57.093971 -2.116218    NJ 9303  osgb   \n",
       "4        AB13   ###   387085    802538  57.113599 -2.214879   NJ 87025  osgb   \n",
       "...       ...   ...      ...       ...        ...       ...        ...   ...   \n",
       "3131     YO91   ###   460504    453656  53.975455 -1.079029  SE 605536  osgb   \n",
       "3132     YS22   ###   493648    507760  54.456617 -0.557006   NZ 93677  osgb   \n",
       "3133      ZE1   ###   446297   1141020  60.151066 -1.167983  HU 462410  osgb   \n",
       "3134      ZE2   ###   444046   1168116  60.394585 -1.202625  HU 440681  osgb   \n",
       "3135      ZE3   ###   439134    967886  58.597195 -1.328406  NE 391678  osgb   \n",
       "\n",
       "                            sources  \n",
       "0       NPE Postcode web submission  \n",
       "1     Dracos.co.uk Postbox Importer  \n",
       "2     Dracos.co.uk Postbox Importer  \n",
       "3     Dracos.co.uk Postbox Importer  \n",
       "4       NPE Postcode web submission  \n",
       "...                             ...  \n",
       "3131    NPE Postcode web submission  \n",
       "3132    NPE Postcode web submission  \n",
       "3133   FreeThePostcode.org Importer  \n",
       "3134  Dracos.co.uk Postbox Importer  \n",
       "3135   FreeThePostcode.org Importer  \n",
       "\n",
       "[3136 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "districts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "079fbe9c-b4c6-4371-94e9-fb655a485c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "prices = pd.read_csv(\"realestate_data_london_2024_nov_trimmed.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1c7122-fd6d-4f81-9b23-ae8d413a5f3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f6efc82-38e3-4a28-b6ed-002e749cac4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prices[\"district\"] = prices[\"title\"].apply(lambda x: x.split(\",\")[-1].strip())\n",
    "prices[\"district\"] = prices[\"district\"].apply(lambda x: x.split(\" \")[-1].strip())\n",
    "\n",
    "df = pd.merge(\n",
    "    prices,\n",
    "    districts,\n",
    "    on='district',    # name of the column in both frames\n",
    "    how='inner'         # keep all rows from df_prices\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea7aaac6-cd8c-4dc8-8163-6c7bc49295ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'E20'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### DISTRICTS IN PRICES BUT NOT POSTCODE LOCATIONS\n",
    "set(prices[\"district\"]) - set(districts[\"district\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "faf5190b-037d-4dba-adc4-bdc59e51ea1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "propertyType\n",
       "Apartment              242\n",
       "Detached               152\n",
       "Terraced               151\n",
       "Flat                   127\n",
       "House                  110\n",
       "Penthouse               94\n",
       "Semi-Detached           37\n",
       "Town House              29\n",
       "End of Terrace          20\n",
       "Duplex                  10\n",
       "Not Specified            8\n",
       "Block of Apartments      7\n",
       "Land                     6\n",
       "Mews                     6\n",
       "Maisonette               6\n",
       "Villa                    4\n",
       "Link Detached House      3\n",
       "Plot                     2\n",
       "Equestrian Facility      2\n",
       "Character Property       1\n",
       "Ground Flat              1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### VALUE COUNTS\n",
    "df[\"propertyType\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd403194-f397-4cc8-b0b7-4b95b8c5d05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [\"Apartment\", \"Flat\", \"Detached\", \"Terraced\", \"House\", \"Penthouse\", \"Semi-Detached\", \"Town House\"]\n",
    "df = df[df[\"propertyType\"].isin(lst)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df963d38-a6b6-4710-b6ae-f9c8b5d27145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'propertyType', 'sizeSqFeetMax', 'bedrooms', 'bathrooms',\n",
       "       'price', 'district', 'blank', 'easting', 'northing', 'lat', 'long',\n",
       "       'NGR', 'grid', 'sources'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "833a5554-7369-4b38-b559-080b9d4cd7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\"price\", \"easting\", \"northing\", \"propertyType\", \"sizeSqFeetMax\", \"bedrooms\", \"bathrooms\"]]\n",
    "df = df[~df[\"easting\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a534d662-d229-4579-a717-5eac218a70ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "price              0\n",
       "easting            0\n",
       "northing           0\n",
       "propertyType       0\n",
       "sizeSqFeetMax    130\n",
       "bedrooms           4\n",
       "bathrooms         22\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### COLUMNS WITH NANS\n",
    "nan_counts = df.isna().sum()\n",
    "nan_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aad3673c-5356-4c1a-abe5-63ad238a834c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sizeSqFeetMax    3795.5\n",
       "bedrooms            5.0\n",
       "bathrooms           4.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### MEDIA AFTER CLEANING BUT BEFORE IMUPTATION\n",
    "df[[\"sizeSqFeetMax\", \"bedrooms\", \"bathrooms\"]].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd05e10c-c0fb-4d09-b259-7b5e7a66eddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies = pd.get_dummies(df['propertyType'], prefix='pt_', dtype=int)\n",
    "\n",
    "# join back to your original df (and optionally drop the original column)\n",
    "df2 = df.drop('propertyType', axis=1).join(dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e2a2418-c4f3-4aeb-a3c8-d2607fe21a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['price_float'] = (\n",
    "    df2['price']\n",
    "      .str.replace('£', '', regex=False)     # drop the £\n",
    "      .str.replace(',', '', regex=False)     # drop the commas\n",
    "      .astype(float)                         # cast to float\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3af0c9b8-9d32-465c-8027-b9bfba6c7edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPUTATION STEP\n",
    "\n",
    "dummies = pd.get_dummies(df['propertyType'], prefix='pt_', dtype=int)\n",
    "df2 = df.drop('propertyType', axis=1).join(dummies)\n",
    "df2['price_float'] = (\n",
    "    df2['price']\n",
    "      .str.replace('£', '', regex=False)     # drop the £\n",
    "      .str.replace(',', '', regex=False)     # drop the commas\n",
    "      .astype(float)                         # cast to float\n",
    ")\n",
    "\n",
    "### FILL BLANKS WITH MEDIAN\n",
    "df_f = df2.drop(columns=[\"price\", \"easting\", \"northing\"])\n",
    "for col in [\"sizeSqFeetMax\", \"bathrooms\", \"bedrooms\"]:\n",
    "    predictors = [c for c in df2.columns if c != col]\n",
    "    df2[col + \"i\"] = df2[col].fillna(\n",
    "        df2[col].median()\n",
    "    )\n",
    "nan_counts = df2.isna().sum()\n",
    "\n",
    "#USE MEDIAN TO CONSTRUCT LINEAR IMPUTATION MODELS\n",
    "model_betas = {}\n",
    "columns = [\"sizeSqFeetMax\", \"bedrooms\", \"bathrooms\"]\n",
    "predictor_all = [\"bedroomsi\", \"bathroomsi\", \"sizeSqFeetMaxi\", \"pt__Apartment\", \"pt__Detached\", \"pt__Flat\", \"pt__House\", \"pt__Penthouse\", \"pt__Semi-Detached\", \"pt__Terraced\", \"pt__Town House\", \"price_float\"]\n",
    "\n",
    "for col in columns:\n",
    "    tmp = df2.dropna()\n",
    "    y = tmp[col].to_numpy()\n",
    "    predictors = [c for c in predictor_all if c != col + \"i\"]\n",
    "    X = tmp[predictors].to_numpy()\n",
    "    beta_hat = np.linalg.inv(X.T @ X) @ (X.T @ y)\n",
    "    model_betas[col] = beta_hat\n",
    "    \n",
    "\n",
    "cols = [\"sizeSqFeetMax\", \"bathrooms\", \"bedrooms\"]\n",
    "for col in [\"sizeSqFeetMax\", \"bathrooms\", \"bedrooms\"]:\n",
    "    predictors = [c for c in predictor_all if c != col + \"i\"]\n",
    "    df2[col] = df2[col].fillna(\n",
    "        df2[predictors].dot(model_betas[col])\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02f4f13e-97dd-4b89-be32-4dd98da28e2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sizeSqFeetMax    4045.581546\n",
       "bedrooms            5.000000\n",
       "bathrooms           4.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[[\"sizeSqFeetMax\", \"bedrooms\", \"bathrooms\"]].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1de2775-ebb4-44fd-9b40-4675bdb48c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full = df2[[\"easting\", \"northing\", \"sizeSqFeetMax\", \"bedrooms\", \"bathrooms\",\"pt__Apartment\", \"pt__Detached\", \"pt__Flat\", \"pt__House\", \"pt__Penthouse\", \"pt__Semi-Detached\", \"pt__Terraced\", \"pt__Town House\"]].to_numpy()\n",
    "\n",
    "y = df2[\"price_float\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5def20-bcbb-4118-8ad3-13b30a181aa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f90dde7-5f53-4b88-8ec3-c77beb9f208a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f74ee92-bcb9-4316-9402-1417c9194b61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2890cf99-d06a-43a3-9e9b-6f6c4ada8dd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a56792cf-8827-4cd9-b8a1-7550cae9b62d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(942, 13)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b6d565d3-c61f-4b61-89a9-16e3b7ed7df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daved\\AppData\\Local\\Temp\\ipykernel_4816\\2710727906.py:134: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  logL   = float(logL)                  # scalar\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3802.5161011723603\n",
      "1270.338588824727\n",
      "1270.0882501919448\n",
      "1269.10253170352\n",
      "1265.4312503842402\n",
      "1265.0240641019832\n",
      "1257.9007061234831\n",
      "1257.1222799368184\n",
      "1256.7963091677755\n",
      "1256.7892882475362\n",
      "1256.7887508303922\n",
      "1256.7861644202321\n",
      "1256.7803845974481\n",
      "1256.7632143635435\n",
      "1256.7101619953833\n",
      "1254.0354281675595\n",
      "1253.7814019234283\n",
      "1253.264333849591\n",
      "1253.2589005653058\n",
      "1253.258857404536\n",
      "1253.25885740057\n",
      "  message: CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH\n",
      "  success: True\n",
      "   status: 0\n",
      "      fun: 1253.25885740057\n",
      "        x: [ 8.559e-01  1.000e-12  3.451e+01]\n",
      "      nit: 17\n",
      "      jac: [-1.933e-06  5.501e+02  7.864e-15]\n",
      "     nfev: 21\n",
      "     njev: 21\n",
      " hess_inv: <3x3 LbfgsInvHessProduct with dtype=float64>\n",
      "Optimized noise var: 0.855928161843549\n",
      "Optimized signal var: 1e-12\n",
      "Optimized lengthscale: 34.51479810749315\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#X_full = df2[[\"easting\", \"northing\", \"sizeSqFeetMax\", \"bedrooms\", \"bathrooms\",\"pt__Apartment\", \"pt__Detached\", \"pt__Flat\", \"pt__House\", \"pt__Penthouse\", \"pt__Semi-Detached\", \"pt__Terraced\", \"pt__Town House\"]].to_numpy()\n",
    "X_full = df2[[\"easting\", \"northing\", \"sizeSqFeetMax\", \"bedrooms\", \"bathrooms\",\"pt__Apartment\", \"pt__Detached\", \"pt__Flat\", \"pt__House\", \"pt__Penthouse\", \"pt__Semi-Detached\", \"pt__Terraced\"]].to_numpy()\n",
    "\n",
    "y = df2[\"price_float\"].to_numpy()\n",
    "X_full[:, :2] = X_full[:, :2] / 10000.0\n",
    "\n",
    "#SCALE FOR STABILITY - REMEMBER TO UNSCALE\n",
    "y = y / df2[\"price_float\"].std()\n",
    "\n",
    "\n",
    "n, D = X_full.shape\n",
    "\n",
    "# Split into spatial vs covariates:\n",
    "s = X_full[:, :2]        # shape (n,2)\n",
    "X = X_full[:, 2:]        # shape (n, p)\n",
    "X = np.hstack([np.ones((X.shape[0], 1)), X])\n",
    "\n",
    "#scaler_X = StandardScaler()\n",
    "#X = scaler_X.fit_transform(X)\n",
    "\n",
    "\n",
    "p = X.shape[1]\n",
    "\n",
    "# Ensure y is a column vector:\n",
    "y = y.reshape(-1, 1)     # shape (n,1)\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 2) Covariance builder\n",
    "# -----------------------------------------------------------------------------\n",
    "def make_K(s, sigma_f2, ell, sigma_n2):\n",
    "    \"\"\"\n",
    "    Build K = K_f + sigma_n2 * I,\n",
    "    where (K_f)_{ij} = sigma_f2 * exp(-0.5 * ||s_i - s_j||^2 / ell^2).\n",
    "    Returns (K, K_f, sq_dists).\n",
    "    \"\"\"\n",
    "    # pairwise squared distances (n×n)\n",
    "    d2 = squareform(pdist(s, 'sqeuclidean'))\n",
    "    K_f = sigma_f2 * np.exp(-0.5 * d2 / ell**2)\n",
    "    return K_f + sigma_n2 * np.eye(len(s)), K_f, d2\n",
    "\n",
    "\n",
    "def near_spd_eig(A, tol=1e-14):\n",
    "    \"\"\"\n",
    "    Projects symmetric A onto the nearest SPD matrix by clipping eigenvalues.\n",
    "    \"\"\"\n",
    "    # (1) Symmetrize\n",
    "    B = (A + A.T) / 2\n",
    "\n",
    "    # (2) Eigendecompose\n",
    "    eigvals, eigvecs = eigh(B)\n",
    "\n",
    "    # (3) Clip negatives to tol\n",
    "    eigvals_clipped = np.clip(eigvals, tol, None)\n",
    "\n",
    "    # (4) Reconstruct, then re-symmetrize\n",
    "    B_psd = (eigvecs * eigvals_clipped) @ eigvecs.T\n",
    "    return (B_psd + B_psd.T) / 2\n",
    "\n",
    "def make_K_higham_eig(s, sigma_f2, ell, sigma_n2, tol=1e-14):\n",
    "    \"\"\"\n",
    "    1) Build raw K_f\n",
    "    2) Project K_f to SPD\n",
    "    3) Add noise sigma_n2*I\n",
    "    4) Project final K to SPD\n",
    "    \"\"\"\n",
    "    # pairwise squared distances\n",
    "    d2 = squareform(pdist(s, 'sqeuclidean'))\n",
    "\n",
    "    # raw kernel\n",
    "    K_f = sigma_f2 * np.exp(-0.5 * d2 / ell**2)\n",
    "    K_f = (K_f + K_f.T) / 2\n",
    "\n",
    "    # project to SPD\n",
    "    Kf_spd = near_spd_eig(K_f, tol=tol)\n",
    "\n",
    "    # add noise\n",
    "    n = K_f.shape[0]\n",
    "    K = Kf_spd + sigma_n2 * np.eye(n)\n",
    "\n",
    "    # final SPD projection\n",
    "    K_spd = near_spd_eig(K, tol=tol)\n",
    "\n",
    "    # diagnostics (optional)\n",
    "    #print(\"min eigen(K_f after proj) =\", np.min(np.linalg.eigvalsh(Kf_spd)))\n",
    "    #print(\"min eigen(final K_spd)   =\", np.min(np.linalg.eigvalsh(K_spd)))\n",
    "\n",
    "    return K_spd, Kf_spd, d2\n",
    "\n",
    "def make_K_fixed(s, sigma_f2, ell, sigma_n2):\n",
    "    # 1) raw squared distances\n",
    "    d2 = squareform(pdist(s, 'sqeuclidean'))\n",
    "\n",
    "    # 2) raw covariance (may be rank-deficient)\n",
    "    K_f = sigma_f2 * np.exp(-0.5 * d2 / ell**2)\n",
    "    K_f = (K_f + K_f.T) / 2   # exact symmetry\n",
    "    # 3) add noise nugget (automatically PD)\n",
    "    n = K_f.shape[0]\n",
    "    K = K_f + sigma_n2 * np.eye(n)\n",
    "    # 4) optionally symmetrize to kill tiny round-off asymmetries\n",
    "    K = (K + K.T) / 2\n",
    "    return K, K_f, d2\n",
    "\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 3) Log-marginal likelihood + gradient (for minimization)\n",
    "# -----------------------------------------------------------------------------\n",
    "def neg_log_marginal_and_grad(theta, s, X, y, return_betas = False):\n",
    "    \"\"\"\n",
    "    Given theta = [sigma_n2, sigma_f2, ell],\n",
    "    returns (neg_logL, neg_grad).\n",
    "    \"\"\"\n",
    "    sigma_n2, sigma_f2, ell = theta\n",
    "    n, p = X.shape\n",
    "    # Build covariance\n",
    "    K, K_f, d2 = make_K_higham_eig(s, sigma_f2, ell, sigma_n2)\n",
    "    #K, K_f, d2 = make_K_fixed(s, sigma_f2, ell, sigma_n2)\n",
    "    # Cholesky factorization of K\n",
    "    L, lower = cho_factor(K, overwrite_a=False)\n",
    "\n",
    "    # 3a) GLS estimate of beta:  beta = (X^T K^{-1} X)^{-1} X^T K^{-1} y\n",
    "    Kinv_y = cho_solve((L, lower), y)      # K^{-1} y\n",
    "    Kinv_X = cho_solve((L, lower), X)      # K^{-1} X\n",
    "    XtKinvX = X.T @ Kinv_X                 # p×p\n",
    "    beta_hat = np.linalg.solve(XtKinvX, X.T @ Kinv_y)  # p×1\n",
    "    # 3b) Residuals under the mean\n",
    "    r = y - X @ beta_hat                   # n×1\n",
    "\n",
    "    # 3c) Log-marginal likelihood\n",
    "    alpha  = cho_solve((L, lower), r)      # K^{-1} r\n",
    "    logdet = 2.0 * np.sum(np.log(np.diag(L)))\n",
    "    logL   = -0.5 * (r.T @ alpha + logdet + (n-p) * np.log(2*np.pi))\n",
    "    logL   = float(logL)                  # scalar\n",
    "\n",
    "    # 4) Gradients w.r.t. each theta_j\n",
    "    # W = alpha alpha^T - K^{-1}\n",
    "    Kinv = lambda M: cho_solve((L, lower), M)\n",
    "    W = alpha @ alpha.T - Kinv(np.eye(n))  # n×n\n",
    "\n",
    "    # Derivatives of K\n",
    "    dK_dsigma_n2 = np.eye(n)\n",
    "    dK_dsigma_f2 = K_f / sigma_f2\n",
    "    dK_dell      = K_f * (d2 / (ell**3))\n",
    "\n",
    "    grad = 0.5 * np.array([\n",
    "        np.trace(W @ dK_dsigma_n2),\n",
    "        np.trace(W @ dK_dsigma_f2),\n",
    "        np.trace(W @ dK_dell)\n",
    "    ])  # shape (3,)\n",
    "\n",
    "    # We minimize, so return negatives:\n",
    "    print(-logL)\n",
    "    if return_betas:\n",
    "        return -logL, -grad, beta_hat    \n",
    "    return -logL, -grad\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 5) Choose an initial guess for [sigma_n2, sigma_f2, ell]\n",
    "# -----------------------------------------------------------------------------\n",
    "init_sigma_n2 = 1e-1\n",
    "init_sigma_f2 = np.var(y)\n",
    "init_ell      = 2 * np.std(s)  # e.g. a few units in your scaled coords\n",
    "\n",
    "theta0 = np.array([init_sigma_n2, init_sigma_f2, init_ell])\n",
    "\n",
    "bounds = [(1e-12, None),   # sigma_n2 ≥ 1e-8\n",
    "          (1e-12, None),   # sigma_f2\n",
    "          (1e-8, None)]\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 6) Run the optimizer\n",
    "# -----------------------------------------------------------------------------\n",
    "res = minimize(\n",
    "    fun    = neg_log_marginal_and_grad,\n",
    "    x0     = theta0,\n",
    "    args   = (s, X, y),\n",
    "    jac    = True,\n",
    "    bounds = bounds,\n",
    "    method = 'L-BFGS-B',         # quasi-Newton; or 'Newton-CG' if you implement Hessian\n",
    "    options= {'disp': True, 'gtol':1e-6}\n",
    ")\n",
    "print(res)\n",
    "sigma_n2_opt, sigma_f2_opt, ell_opt = res.x\n",
    "print(\"Optimized noise var:\",    sigma_n2_opt)\n",
    "print(\"Optimized signal var:\",   sigma_f2_opt)\n",
    "print(\"Optimized lengthscale:\",  ell_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33b53578-0afa-4beb-b54a-37bc65f32756",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daved\\AppData\\Local\\Temp\\ipykernel_4816\\2710727906.py:134: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  logL   = float(logL)                  # scalar\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1253.25885740057\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 1.43406245e+00],\n",
       "        [ 6.85552760e-06],\n",
       "        [-6.01763102e-02],\n",
       "        [ 1.93719523e-01],\n",
       "        [-4.94452141e-01],\n",
       "        [-5.09666975e-01],\n",
       "        [-5.80790219e-01],\n",
       "        [-2.22977828e-01],\n",
       "        [-2.98040943e-01],\n",
       "        [-2.90671788e-01],\n",
       "        [-3.41166646e-01]]),\n",
       " array([[ 9.81037472e+06],\n",
       "        [ 4.68984419e+01],\n",
       "        [-4.11664185e+05],\n",
       "        [ 1.32522897e+06],\n",
       "        [-3.38253105e+06],\n",
       "        [-3.48661524e+06],\n",
       "        [-3.97316704e+06],\n",
       "        [-1.52538409e+06],\n",
       "        [-2.03888842e+06],\n",
       "        [-1.98847627e+06],\n",
       "        [-2.33390995e+06]]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l,g,beta = neg_log_marginal_and_grad([sigma_n2_opt, sigma_f2_opt, ell_opt], s, X, y, True)\n",
    "beta_unscaled = beta *  df2[\"price_float\"].std()\n",
    "\n",
    "### CORRECT VALUES IN BETA UNSCALED (REMEMBER TO UNSCALE)\n",
    "beta, beta_unscaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c6e96561-42ad-4db4-835d-2968b46ffea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred = np.dot(X, beta) #+ intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c6d147-ca47-4a1a-bdd8-ef3a56839e39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a0e50b-c78f-4362-ae61-162835be5a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb64b2da-5978-4f04-9523-a0511d445e56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d6d986f-254b-4bdc-a2d2-29d7858109da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9.81037472e+06,  4.68984419e+01, -4.11664185e+05,  1.32522897e+06,\n",
       "       -3.38253105e+06, -3.48661524e+06, -3.97316704e+06, -1.52538409e+06,\n",
       "       -2.03888842e+06, -1.98847627e+06, -2.33390995e+06])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###CHECK YOU GET THE SAME VALUES WITHOUT INEEFECTIVE SPATIAL PARAMETER\n",
    "X_ = df2[[\"sizeSqFeetMax\", \"bedrooms\", \"bathrooms\",\"pt__Apartment\", \"pt__Detached\", \"pt__Flat\", \"pt__House\", \"pt__Penthouse\", \"pt__Semi-Detached\", \"pt__Terraced\"]].to_numpy()\n",
    "X_ = np.hstack([np.ones((X_.shape[0], 1)), X_])\n",
    "\n",
    "y_ = df2[\"price_float\"].to_numpy()#/ df2[\"price_float\"].std()\n",
    "\n",
    "XtX = X_.T @ X_              # shape (p, p)\n",
    "XtX_inv = np.linalg.inv(XtX)\n",
    "Xty = X_.T @ y_              # shape (p,)\n",
    "beta_hat = XtX_inv @ Xty   \n",
    "beta_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e512b64a-6254-43f7-970a-255b3677bdde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e835dea8-9eb4-47d7-9696-da9eb763c42c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d35c33c-d21c-4c26-82a3-5f49821c27e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e53d232",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ec66a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28056b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbeaceef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0c166a-2106-4a25-80d4-801d1769af33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1faf7bc3-b0f9-456d-8ea9-2eb84abce2fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528feba7-1fca-486f-919b-00d0fb6d9f53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f589f8a8-7fd1-48bf-8fbd-b120a2e436ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.linalg        import cho_solve, cho_factor\n",
    "\n",
    "# --- 1) Your trained params and data (replace these) -----------------------\n",
    "sigma_n2, sigma_f2, ell = sigma_n2_opt, sigma_f2_opt, ell_opt\n",
    "s_train = s                        # (n,2) spatial coords from your data\n",
    "X_train = X                        # (n,p) covariates\n",
    "y_train = y.flatten()              # (n,)\n",
    "# your fitted regression weights:\n",
    "_, _, beta_hat = neg_log_marginal_and_grad(\n",
    "    [sigma_n2, sigma_f2, ell], s, X, y, return_betas=True)\n",
    "\n",
    "# build and factor the training covariance\n",
    "K = make_K(s_train, sigma_f2, ell, sigma_n2)[0]\n",
    "L, lower = cho_factor(K, check_finite=False)\n",
    "\n",
    "# --- 2) Fix non‐spatial covariates to their means --------------------------\n",
    "x_ref = np.mean(X_train, axis=0)   # (p,)\n",
    "\n",
    "# --- 3) Build grid over spatial domain -------------------------------------\n",
    "nx = ny = 100\n",
    "x1 = np.linspace(s_train[:,0].min(), s_train[:,0].max(), nx)\n",
    "x2 = np.linspace(s_train[:,1].min(), s_train[:,1].max(), ny)\n",
    "X1, X2 = np.meshgrid(x1, x2)\n",
    "grid_pts = np.column_stack([X1.ravel(), X2.ravel()])  # (nx*ny, 2)\n",
    "\n",
    "# replicate reference covariates for each grid point\n",
    "X_ref = np.tile(x_ref, (grid_pts.shape[0], 1))        # (nx*ny, p)\n",
    "\n",
    "# --- 4) Compute cross‐covariance and GP mean -------------------------------\n",
    "# k(s_train, grid)\n",
    "d2 = cdist(s_train, grid_pts, 'sqeuclidean')\n",
    "K_star = sigma_f2 * np.exp(-0.5 * d2 / ell**2)       # (n, nx*ny)\n",
    "\n",
    "# residuals (y - X beta)\n",
    "resid = y_train - X_train.dot(beta_hat).flatten()\n",
    "\n",
    "# predictive mean of the zero‐mean GP part\n",
    "alpha = cho_solve((L, lower), resid)                 # (n,)\n",
    "mu_gp = K_star.T.dot(alpha)                          # (nx*ny,)\n",
    "\n",
    "# add back the linear mean X_* β\n",
    "mu_lin = X_ref.dot(beta_hat).flatten()               # (nx*ny,)\n",
    "mu = mu_gp + mu_lin\n",
    "\n",
    "# reshape to grid\n",
    "MU = mu.reshape(ny, nx)\n",
    "\n",
    "# --- 5) Plot ---------------------------------------------------------------\n",
    "plt.figure(figsize=(6,5))\n",
    "pcm = plt.pcolormesh(X1, X2, MU, shading='auto')\n",
    "plt.scatter(s_train[:,0], s_train[:,1], c=y_train, edgecolor='k', cmap='viridis')\n",
    "plt.colorbar(pcm, label='Predicted response')\n",
    "plt.xlabel('Easting (×10000)')\n",
    "plt.ylabel('Northing (×10000)')\n",
    "#plt.title('GP spatial effect + covariate mean')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CALFEM • Py 3.10 (Qt5)",
   "language": "python",
   "name": "calfem-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
